{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "import statsmodels.api as sm\n",
    "from line_profiler import LineProfiler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grouped_data(seed=1):\n",
    "    \"\"\" Generate random gaussian data with a given seed \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_cols = 1\n",
    "    n_rows = 2**11\n",
    "    random_data = np.random.normal(size=n_cols * n_rows, scale=4)\n",
    "    random_data = random_data.reshape(n_rows, n_cols)\n",
    "    random_df = pd.DataFrame(random_data)\n",
    "    random_df['group'] = np.arange(len(random_df)) % 15\n",
    "    return random_df\n",
    "\n",
    "df = generate_grouped_data()\n",
    "df['group'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_groupby_lstsq(series):\n",
    "    lenght_x = series.shape[0]\n",
    "    X = np.arange(lenght_x)\n",
    "    ones = np.ones(lenght_x)\n",
    "    X = np.vstack((X, ones)).T\n",
    "    slope, intercept = np.linalg.lstsq(X, series, rcond=-1)[0]\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "slopes_by_group = df.groupby('group')[0].transform(ols_groupby_lstsq)\n",
    "slopes_by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def ols_groupby_lstsq_numba(series):\n",
    "    lenght_x = series.shape[0]\n",
    "    X = np.arange(lenght_x)\n",
    "    ones = np.ones(lenght_x)\n",
    "    X = np.vstack((X, ones)).T\n",
    "    slope, intercept = np.linalg.lstsq(X, series.values, rcond=-1)[0]\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# slopes_by_group = df.groupby('group')[0].transform(ols_groupby_lstsq_numba)\n",
    "# slopes_by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "# @numba.jit(nopython=True)\n",
    "def get_group_ixs(ids):\n",
    "    id_hash = defaultdict(list)\n",
    "    for j, key in enumerate(ids):\n",
    "        id_hash[key].append(j)\n",
    "    id_hash = {k: np.array(v) for k, v in id_hash.items()}\n",
    "    return id_hash\n",
    "\n",
    "def group_apply(values, group_ids, func):\n",
    "    output = np.repeat(np.nan, len(values))\n",
    "    ixs = get_group_ixs(group_ids)\n",
    "    for ix in ixs.values():\n",
    "        output[ix] = func(values[ix])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:1][0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @numba.jit(nopython=True)\n",
    "def ols_group_ixs(array):\n",
    "    lenght_x = array.shape[0]\n",
    "    X = np.arange(lenght_x)\n",
    "    ones = np.ones(lenght_x)\n",
    "    X = np.vstack((X, ones)).T\n",
    "    slope = np.linalg.lstsq(X, array, rcond=-1)[0][0]\n",
    "    return slope\n",
    "\n",
    "\n",
    "results_manual_group_apply = group_apply(df.iloc[:1]['group'].values, df.iloc[:1][0].values, ols_group_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "results_sm = group_apply(df['group'].values, df[0].values, ols_group_ixs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask\n",
    "\n",
    "- Pandas and Numpy distributed computing\n",
    "- Bag (standard Python collections), Array(NumPy) and Distributed DataFrame (Pandas)\n",
    "- Super-easy parallelised Pandas functions\n",
    "\n",
    "Dask official documentation: https://docs.dask.org/en/latest/dataframe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "N_PARTITIONS = 16\n",
    "SCHEDULER = \"processes\"\n",
    "ddf = dd.from_pandas(df, npartitions=N_PARTITIONS, sort=False)\n",
    "slopes = ddf.groupby(\"group\")[0].transform(\n",
    "    ols_groupby_lstsq,\n",
    "    axis=1,\n",
    "    meta=(None, 'float64'),\n",
    "    raw=True,\n",
    ").compute(scheduler=SCHEDULER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
